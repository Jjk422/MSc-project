{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part of speech grammer parser\n",
    "Use template to grab words that fit with the part of speech grammar pattern.  \n",
    "Examples of the format of the grammar parser are:  \n",
    "* `<DT><NN><VB><NN>`\n",
    " * Returns `<DT><NN><VBZ><NN>`\n",
    " * e.g. The cat plays piano\n",
    "* `!<DT><NN><VB><NN>`\n",
    " * Returns `<NN><VBZ><NN>`\n",
    " * e.g. cat plays piano\n",
    "* `<DT><NN>*<NN>`\n",
    " * Returns `<DT><NN><VBZ><NN>`\n",
    " * e.g. The cat plays piano\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "conjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['is', 'of', '::process'], ['of', 'of', '::process', '::process']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::tool'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['determine', 'resolve', '::cause'], ['resolve', 'resolve', '::cause', '::cause']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::incident'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['detect', 'prevent', '::future problems/incidents'], ['prevent', 'prevent', '::future problems/incidents', '::future problems/incidents']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::problem'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::separate Incident'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['be', '::action'], ['be', 'be', '::action', '::action']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['be', '::visibility'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::user request'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['manage', '::information'], ['manage', 'manage', '::information', '::information']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::others'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::user request'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::record'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::process flow'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['manage', '::ability'], ['manage', 'manage', '::ability', '::ability']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::Management'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['be', 'during', '::Service Operation'], ['during', 'during', '::Service Operation', '::Service Operation']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['are', 'during', '::other phase'], ['are', 'are', 'during', 'during', '::other phase', '::other phase']]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::include'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::Availability Management'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: [['::Measurement'], []]\n----------------------------------------------------------------------------------------------------\nontology: {}\nconjunctive_relation: []\n----------------------------------------------------------------------------------------------------\nontology: {}\nontology_main: {}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import nltk\n",
    "# sentence = \"The cat plays piano.\"\n",
    "\n",
    "with open(\"ITIL Books/ITIL 3/Service operation chapter 4/Service operation chapter 4 - 4.txt\") as file:\n",
    "    file_contents = file.read()\n",
    "    \n",
    "sentences = nltk.tokenize.sent_tokenize(file_contents)\n",
    "\n",
    "sentence = \"Event Management is the process that monitors all events that occur through the IT infrastructure to allow for normal operation and also to detect and escalate exception conditions.\"\n",
    "\n",
    "ontology_main = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    ontology = {}\n",
    "    \n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    ### Part of speech tagging ###\n",
    "    part_of_speech_array = nltk.pos_tag(tokens)\n",
    "    # print(part_of_speech_array)\n",
    "    # print(\"-\" * 100)\n",
    "    \n",
    "    # def search_pos_sentence_with_grammar(grammar, sentence, ordering):\n",
    "    #     tags_to_search_for = []\n",
    "    #     for all_pos_tags in grammar:\n",
    "    #         all_pos_tags = all_pos_tags.split(\"/\")\n",
    "    #         # print(all_pos_tags)\n",
    "    #         tags_to_search_for.append(all_pos_tags)\n",
    "    #         \n",
    "    #     print(tags_to_search_for)\n",
    "    #     \n",
    "    #     phrase = []\n",
    "    #     found_start_word = False\n",
    "    #     tag_count = 0\n",
    "    #     word_count = 0\n",
    "    #     for pos_word in sentence:\n",
    "    #         if tag_count < len(tags_to_search_for) and pos_word[1] in tags_to_search_for[tag_count]:\n",
    "    #             if ordering is True:\n",
    "    #                 \n",
    "    #             tag_count = tag_count + 1\n",
    "    #             phrase.append(pos_word)\n",
    "    #         word_count = word_count + 1\n",
    "    #     print(phrase)\n",
    "    #     return phrase\n",
    "    #         \n",
    "    #         \n",
    "    #     \n",
    "    #         \n",
    "    # def pos_grammar_parse(grammar, sentence, ordering=False):\n",
    "    #     grammar = [item.replace(\"<\", \"\").upper() for item in grammar.split(\">\") if item is not '']\n",
    "    #     # grammar = [item.split(\"/\") for item in grammar]\n",
    "    #     # print(grammar)\n",
    "    #     return search_pos_sentence_with_grammar(grammar, sentence, ordering)\n",
    "    #     # print(grammar)\n",
    "    \n",
    "    #%%\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    part_of_speech_array_lemmatized = []\n",
    "    \n",
    "    for part_of_speech in part_of_speech_array:\n",
    "        part_of_speech_array_lemmatized.append(\n",
    "            (lemmatizer.lemmatize(part_of_speech[0]), part_of_speech[1])\n",
    "        ) \n",
    "    \n",
    "    # print(part_of_speech_array_lemmatized)\n",
    "    \n",
    "    # print(part_of_speech_array)\n",
    "    \n",
    "    #%%\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    part_of_speech_array_lemmatized_no_stopwords = [word_pos for word_pos in part_of_speech_array_lemmatized if not word_pos[0] in stop_words]\n",
    "    \n",
    "    # print(part_of_speech_array_lemmatized_no_stopwords)\n",
    "    \n",
    "    #%%\n",
    "    # noun_phrase_grammar = \"NP: {<DT>?<JJ>*<NN|NNP|NNS>*}\"\n",
    "    # noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>*}\"\n",
    "    noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>+}\"\n",
    "    # print(pos_grammar_parse(grammar, part_of_speech_array))\n",
    "    \n",
    "    regex = nltk.RegexpParser(noun_phrase_grammar)\n",
    "    noun_phrases_chunked = regex.parse(part_of_speech_array_lemmatized)\n",
    "    noun_phrases = [item for item in noun_phrases_chunked.subtrees() if item.label() == \"NP\"]\n",
    "    \n",
    "    # print(noun_phrases)\n",
    "    \n",
    "    # for item in noun_phrases_chunked:\n",
    "    #     print(item)\n",
    "    # print()\n",
    "    # \n",
    "    # for concept in noun_phrases:\n",
    "    #     print(concept)\n",
    "    #     \n",
    "    # print()\n",
    "    \n",
    "    # relation_grammer = \"\"\"\n",
    "    #     Relation: {<NP>?.*?<VBZ|VBP|IN|VB>+.*?<NP>?}\n",
    "    #     \"\"\"\n",
    "    \n",
    "    relation_grammer = \"\"\"\n",
    "        Relation: {.*?<VBZ|VBP|IN|VB>+.*?}\n",
    "        \"\"\"\n",
    "    regex = nltk.RegexpParser(relation_grammer)\n",
    "    parser = regex.parse(noun_phrases_chunked)\n",
    "    # relation_phrases = [item for item in parser.subtrees() if item.label() == \"Relation\"]\n",
    "    # \n",
    "    # # print(relation_phrases)\n",
    "    # \n",
    "    # # for parse in parser:\n",
    "    # #     print(parse)\n",
    "    # \n",
    "    # relation_new = []\n",
    "    # # TODO: Find a less hacky way to do this\n",
    "    # for index, relation in enumerate(relation_phrases):\n",
    "    #     # print(relation)\n",
    "    # \n",
    "    #     temp_relation = []\n",
    "    #     if index is not 0:\n",
    "    #         temp_relation.append(relation_phrases)\n",
    "    #         temp_relation.append(item for item in relation)\n",
    "    #         # print(f\"TEMP RELATION: {temp_relation}\")\n",
    "    #         relation = temp_relation\n",
    "    # \n",
    "    #     # print(temp_relation)\n",
    "    #     relation_new.append(relation)\n",
    "    #     # print(relation_new)\n",
    "    # \n",
    "    # print()\n",
    "    # \n",
    "    # # for relation in relation_new:\n",
    "    # #     for item in relation:\n",
    "    # #         print(item)\n",
    "    #     \n",
    "    # for relation in relation_phrases:\n",
    "    #     print(relation)\n",
    "    \n",
    "    # for element in parser.subtrees():\n",
    "    #     if element.label() in ['NP', 'Relation']:\n",
    "    #         print(element)\n",
    "            \n",
    "    # Chunk conjunctives\n",
    "    conjunctive_grammer = \"Conjunctive: {.*?<CC>+.*?}\"\n",
    "    regex = nltk.RegexpParser(conjunctive_grammer)\n",
    "    parser = regex.parse(parser)\n",
    "    \n",
    "    # print(parser)\n",
    "    \n",
    "    # for element in parser.subtrees():\n",
    "    #     if element.label() in ['NP', 'Relation', 'Conjunctive']:\n",
    "    #         print(element)\n",
    "    \n",
    "    relations = [element for element in parser.subtrees() if element.label() in ['NP', 'Relation', 'Conjunctive']]\n",
    "    \n",
    "    noun_phrase_indexes = [index for index, element in enumerate(relations) if element.label() == \"NP\"]\n",
    "    \n",
    "    # print(noun_phrase_indexes)\n",
    "    \n",
    "    relationships = []\n",
    "    for index, element in enumerate(noun_phrase_indexes[::2]):\n",
    "        relationships.append(relations[noun_phrase_indexes[index]:noun_phrase_indexes[index + 1] + 1:])\n",
    "    \n",
    "    # ontology = {}\n",
    "        \n",
    "    # print(sentence)    \n",
    "    \n",
    "    for relationship in relationships:\n",
    "        conjunctive_relation = []\n",
    "        temp_relation = []\n",
    "        \n",
    "        first_concept = \" \".join([i[0] for i in relationship[0].leaves()])\n",
    "        \n",
    "        # print(first_concept.replace(\"¦ \", \"\"))\n",
    "        \n",
    "        # TODO: Make this work better make conjuctive relation addative\n",
    "        # In other words make conjunctive into [[]] with words added to [[\"is\", \"here\"]]\n",
    "        # then use conjunctive to add new value so [[\"is\", \"here\"], [\"is\", \"an\", \"animal\"]]\n",
    "        for element in relationship[1::]:\n",
    "            if element.label() == \"Relation\":\n",
    "                temp_relation.append(\" \".join(i[0] for i in element.leaves()))\n",
    "                for conjunctive_list in conjunctive_relation[::]:\n",
    "                    conjunctive_relation[-1].append(\" \".join(i[0] for i in element.leaves()))\n",
    "            elif element.label() == \"Conjunctive\":\n",
    "                conjunctive_relation.append(temp_relation)\n",
    "                conjunctive_relation.append(temp_relation[:-1:])\n",
    "                \n",
    "                # for conjuctive_list in conjunctive_relation:\n",
    "                # temp_relation.append(\" \".join(i[0] for i in element.leaves()))\n",
    "                # conjunctive_relation.append(temp_relation)\n",
    "                # conjunctive_relation.append(temp_relation[:-1:].append(\" \".join(i[0] for i in element.leaves())))\n",
    "                \n",
    "            elif element.label() == \"NP\":\n",
    "                temp_relation.append(\"::\" + \" \".join(i[0] for i in element.leaves()))\n",
    "                for conjuctive_list in conjunctive_relation:\n",
    "                    conjunctive_list.append(\"::\" + \" \".join(i[0] for i in element.leaves()))\n",
    "            # print(element)\n",
    "            \n",
    "            # print(element)\n",
    "        # print(temp_relation)\n",
    "        print(f\"conjunctive_relation: {conjunctive_relation}\")\n",
    "\n",
    "        print(\"-\" * 100)\n",
    "            \n",
    "        # first_concept = \" \".join([i[0] for i in relationship[0].leaves()])\n",
    "        # \n",
    "        # rel = \" \".join(\" \".join([j[0] for j in i.leaves()]) for i in relationship[1::] if i.label() != \"NP\")\n",
    "        # rel = f\"{rel}::{' '.join([i[0] for i in relationship[-1].leaves()])}\"\n",
    "        # \n",
    "        # if first_concept not in ontology.keys():\n",
    "        #     ontology[first_concept] = []\n",
    "        # ontology[first_concept].append(rel)\n",
    "        \n",
    "        print(f\"ontology: {ontology}\")\n",
    "    \n",
    "        for element, value in ontology:\n",
    "            ontology_main[element] = ontology_main[element].append[value.flatten]\n",
    "        \n",
    "print(f\"ontology_main: {ontology_main}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'cat': ['play::piano']}\n----------------------------------------------------------------------------------------------------\n{'Event Management process': ['monitor::event'], 'event': ['occur::IT infrastructure'], 'IT infrastructure': ['allow::normal operation']}\n----------------------------------------------------------------------------------------------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Methods fot non conjunctive relation selections (ises code from iteration_2_part_of_speech_grammar_parser)\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# sentence = \"The cat plays piano.\"\n",
    "sentence = \"Event Management is the process that monitors all events that occur through the IT infrastructure to allow for normal operation and also to detect and escalate exception conditions.\"\n",
    "\n",
    "def tokenize_sentence(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    return nltk.pos_tag(tokens)\n",
    "    \n",
    "def lemmatize_tokens(part_of_speech_array):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    part_of_speech_array_lemmatized = []\n",
    "    \n",
    "    for part_of_speech in part_of_speech_array:\n",
    "        part_of_speech_array_lemmatized.append(\n",
    "            (lemmatizer.lemmatize(part_of_speech[0]), part_of_speech[1])\n",
    "        )\n",
    "    return part_of_speech_array_lemmatized\n",
    "\n",
    "def remove_stopwords_from_tokens(part_of_speech_array_lemmatized):\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    part_of_speech_array_lemmatized_no_stopwords = [word_pos for word_pos in part_of_speech_array_lemmatized if not word_pos[0] in stop_words]\n",
    "    \n",
    "    return part_of_speech_array_lemmatized_no_stopwords\n",
    "\n",
    "def get_noun_phrases(part_of_speech_array_lemmatized):\n",
    "    noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>+}\"\n",
    "    \n",
    "    regex = nltk.RegexpParser(noun_phrase_grammar)\n",
    "    noun_phrases_chunked = regex.parse(part_of_speech_array_lemmatized)\n",
    "    noun_phrases = [item for item in noun_phrases_chunked.subtrees() if item.label() == \"NP\"]\n",
    "    \n",
    "    return noun_phrases_chunked, noun_phrases\n",
    "\n",
    "def get_relations(noun_phrases_chunked):\n",
    "    relation_grammer = \"\"\"\n",
    "    Relation: {.*?<VBZ|VBP|IN|VB>+.*?}\n",
    "    \"\"\"\n",
    "    regex = nltk.RegexpParser(relation_grammer)\n",
    "    parser = regex.parse(noun_phrases_chunked)\n",
    "            \n",
    "    # Chunk conjunctives\n",
    "    conjunctive_grammer = \"Conjunctive: {.*?<CC>+.*?}\"\n",
    "    regex = nltk.RegexpParser(conjunctive_grammer)\n",
    "    parser = regex.parse(parser)\n",
    "    \n",
    "    relations = [element for element in parser.subtrees() if element.label() in ['NP', 'Relation', 'Conjunctive']]\n",
    "    \n",
    "    noun_phrase_indexes = [index for index, element in enumerate(relations) if element.label() == \"NP\"]\n",
    "        \n",
    "    relationships = []\n",
    "    for index, element in enumerate(noun_phrase_indexes[::2]):\n",
    "        relationships.append(relations[noun_phrase_indexes[index]:noun_phrase_indexes[index + 1] + 1:])\n",
    "        \n",
    "    return relationships\n",
    "\n",
    "\n",
    "def create_ontology(relationships):    \n",
    "    ontology = {}\n",
    "        \n",
    "    for relationship in relationships:\n",
    "        temp_relation = []\n",
    "        \n",
    "        first_concept = \" \".join([i[0] for i in relationship[0].leaves()])\n",
    "        \n",
    "        rel = \" \".join(\" \".join([j[0] for j in i.leaves()]) for i in relationship[1::] if i.label() != \"NP\")\n",
    "        rel = f\"{rel}::{' '.join([i[0] for i in relationship[-1].leaves()])}\"\n",
    "        \n",
    "        if first_concept not in ontology.keys():\n",
    "            ontology[first_concept] = []\n",
    "        ontology[first_concept].append(rel)\n",
    "        \n",
    "    return ontology\n",
    "\n",
    "sentences = [\n",
    "    \"The cat plays piano.\",\n",
    "    \"Event Management is a process that monitors all events that occur through the IT infrastructure to allow for normal operation and also to detect and escalate exception conditions.\"\n",
    "]\n",
    "\n",
    "import re\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokenised_sentence = tokenize_sentence(sentence)\n",
    "    lemmatized_tokens = lemmatize_tokens(tokenised_sentence)\n",
    "    tokens_with_removed_stopwords = remove_stopwords_from_tokens(lemmatized_tokens)\n",
    "    noun_phrases_chunked, noun_phrases = get_noun_phrases(tokens_with_removed_stopwords)\n",
    "    relationships = get_relations(noun_phrases_chunked)\n",
    "    ontology = create_ontology(relationships)\n",
    "        \n",
    "    # print(ontology)\n",
    "    for key, value in ontology.items():\n",
    "        ontology[key] = [i for i in value if re.search(\".+::.+\", i)]\n",
    "        \n",
    "        # if key not in ontology_main.keys():\n",
    "        #     ontology_main[key] = []            \n",
    "        # print(ontology_main)\n",
    "        # ontology_main[key] = [ontology_main[key].append(value) for key, value in ontology.items()]\n",
    "\n",
    "    print(ontology)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "# print(ontology_main)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}