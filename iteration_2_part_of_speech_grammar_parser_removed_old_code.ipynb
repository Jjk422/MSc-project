{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part of speech grammer parser\n",
    "Use template to grab words that fit with the part of speech grammar pattern.  \n",
    "Examples of the format of the grammar parser are:  \n",
    "* `<DT><NN><VB><NN>`\n",
    " * Returns `<DT><NN><VBZ><NN>`\n",
    " * e.g. The cat plays piano\n",
    "* `!<DT><NN><VB><NN>`\n",
    " * Returns `<NN><VBZ><NN>`\n",
    " * e.g. cat plays piano\n",
    "* `<DT><NN>*<NN>`\n",
    " * Returns `<DT><NN><VBZ><NN>`\n",
    " * e.g. The cat plays piano\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['is', 'of', '::process'], ['of', 'of', '::process', '::process']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::tool'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['determine', 'resolve', '::cause'], ['resolve', 'resolve', '::cause', '::cause']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::incident'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['detect', 'prevent', '::future problems/incidents'], ['prevent', 'prevent', '::future problems/incidents', '::future problems/incidents']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::problem'], []]\n----------------------------------------------------------------------------------------------------\n[['::separate Incident'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['be', '::action'], ['be', 'be', '::action', '::action']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['be', '::visibility'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::user request'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['manage', '::information'], ['manage', 'manage', '::information', '::information']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::others'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::user request'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::record'], []]\n----------------------------------------------------------------------------------------------------\n[['::process flow'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['manage', '::ability'], ['manage', 'manage', '::ability', '::ability']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::Management'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['be', 'during', '::Service Operation'], ['during', 'during', '::Service Operation', '::Service Operation']]\n----------------------------------------------------------------------------------------------------\n[['are', 'during', '::other phase'], ['are', 'are', 'during', 'during', '::other phase', '::other phase']]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::include'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::Availability Management'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n[['::Measurement'], []]\n----------------------------------------------------------------------------------------------------\n[]\n----------------------------------------------------------------------------------------------------\n{}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import nltk\n",
    "# sentence = \"The cat plays piano.\"\n",
    "\n",
    "with open(\"ITIL Books/ITIL 3/Service operation chapter 4/Service operation chapter 4 - 4.txt\") as file:\n",
    "    file_contents = file.read()\n",
    "    \n",
    "sentences = nltk.tokenize.sent_tokenize(file_contents)\n",
    "\n",
    "sentence = \"Event Management is the process that monitors all events that occur through the IT infrastructure to allow for normal operation and also to detect and escalate exception conditions.\"\n",
    "\n",
    "ontology = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    ### Part of speech tagging ###\n",
    "    part_of_speech_array = nltk.pos_tag(tokens)\n",
    "    # print(part_of_speech_array)\n",
    "    # print(\"-\" * 100)\n",
    "    \n",
    "    # def search_pos_sentence_with_grammar(grammar, sentence, ordering):\n",
    "    #     tags_to_search_for = []\n",
    "    #     for all_pos_tags in grammar:\n",
    "    #         all_pos_tags = all_pos_tags.split(\"/\")\n",
    "    #         # print(all_pos_tags)\n",
    "    #         tags_to_search_for.append(all_pos_tags)\n",
    "    #         \n",
    "    #     print(tags_to_search_for)\n",
    "    #     \n",
    "    #     phrase = []\n",
    "    #     found_start_word = False\n",
    "    #     tag_count = 0\n",
    "    #     word_count = 0\n",
    "    #     for pos_word in sentence:\n",
    "    #         if tag_count < len(tags_to_search_for) and pos_word[1] in tags_to_search_for[tag_count]:\n",
    "    #             if ordering is True:\n",
    "    #                 \n",
    "    #             tag_count = tag_count + 1\n",
    "    #             phrase.append(pos_word)\n",
    "    #         word_count = word_count + 1\n",
    "    #     print(phrase)\n",
    "    #     return phrase\n",
    "    #         \n",
    "    #         \n",
    "    #     \n",
    "    #         \n",
    "    # def pos_grammar_parse(grammar, sentence, ordering=False):\n",
    "    #     grammar = [item.replace(\"<\", \"\").upper() for item in grammar.split(\">\") if item is not '']\n",
    "    #     # grammar = [item.split(\"/\") for item in grammar]\n",
    "    #     # print(grammar)\n",
    "    #     return search_pos_sentence_with_grammar(grammar, sentence, ordering)\n",
    "    #     # print(grammar)\n",
    "    \n",
    "    #%%\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    part_of_speech_array_lemmatized = []\n",
    "    \n",
    "    for part_of_speech in part_of_speech_array:\n",
    "        part_of_speech_array_lemmatized.append(\n",
    "            (lemmatizer.lemmatize(part_of_speech[0]), part_of_speech[1])\n",
    "        ) \n",
    "    \n",
    "    # print(part_of_speech_array_lemmatized)\n",
    "    \n",
    "    # print(part_of_speech_array)\n",
    "    \n",
    "    #%%\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    part_of_speech_array_lemmatized_no_stopwords = [word_pos for word_pos in part_of_speech_array_lemmatized if not word_pos[0] in stop_words]\n",
    "    \n",
    "    # print(part_of_speech_array_lemmatized_no_stopwords)\n",
    "    \n",
    "    #%%\n",
    "    # noun_phrase_grammar = \"NP: {<DT>?<JJ>*<NN|NNP|NNS>*}\"\n",
    "    # noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>*}\"\n",
    "    noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>+}\"\n",
    "    # print(pos_grammar_parse(grammar, part_of_speech_array))\n",
    "    \n",
    "    regex = nltk.RegexpParser(noun_phrase_grammar)\n",
    "    noun_phrases_chunked = regex.parse(part_of_speech_array_lemmatized)\n",
    "    noun_phrases = [item for item in noun_phrases_chunked.subtrees() if item.label() == \"NP\"]\n",
    "    \n",
    "    # print(noun_phrases)\n",
    "    \n",
    "    # for item in noun_phrases_chunked:\n",
    "    #     print(item)\n",
    "    # print()\n",
    "    # \n",
    "    # for concept in noun_phrases:\n",
    "    #     print(concept)\n",
    "    #     \n",
    "    # print()\n",
    "    \n",
    "    # relation_grammer = \"\"\"\n",
    "    #     Relation: {<NP>?.*?<VBZ|VBP|IN|VB>+.*?<NP>?}\n",
    "    #     \"\"\"\n",
    "    \n",
    "    relation_grammer = \"\"\"\n",
    "        Relation: {.*?<VBZ|VBP|IN|VB>+.*?}\n",
    "        \"\"\"\n",
    "    regex = nltk.RegexpParser(relation_grammer)\n",
    "    parser = regex.parse(noun_phrases_chunked)\n",
    "    # relation_phrases = [item for item in parser.subtrees() if item.label() == \"Relation\"]\n",
    "    # \n",
    "    # # print(relation_phrases)\n",
    "    # \n",
    "    # # for parse in parser:\n",
    "    # #     print(parse)\n",
    "    # \n",
    "    # relation_new = []\n",
    "    # # TODO: Find a less hacky way to do this\n",
    "    # for index, relation in enumerate(relation_phrases):\n",
    "    #     # print(relation)\n",
    "    # \n",
    "    #     temp_relation = []\n",
    "    #     if index is not 0:\n",
    "    #         temp_relation.append(relation_phrases)\n",
    "    #         temp_relation.append(item for item in relation)\n",
    "    #         # print(f\"TEMP RELATION: {temp_relation}\")\n",
    "    #         relation = temp_relation\n",
    "    # \n",
    "    #     # print(temp_relation)\n",
    "    #     relation_new.append(relation)\n",
    "    #     # print(relation_new)\n",
    "    # \n",
    "    # print()\n",
    "    # \n",
    "    # # for relation in relation_new:\n",
    "    # #     for item in relation:\n",
    "    # #         print(item)\n",
    "    #     \n",
    "    # for relation in relation_phrases:\n",
    "    #     print(relation)\n",
    "    \n",
    "    # for element in parser.subtrees():\n",
    "    #     if element.label() in ['NP', 'Relation']:\n",
    "    #         print(element)\n",
    "            \n",
    "    # Chunk conjunctives\n",
    "    conjunctive_grammer = \"Conjunctive: {.*?<CC>+.*?}\"\n",
    "    regex = nltk.RegexpParser(conjunctive_grammer)\n",
    "    parser = regex.parse(parser)\n",
    "    \n",
    "    # print(parser)\n",
    "    \n",
    "    # for element in parser.subtrees():\n",
    "    #     if element.label() in ['NP', 'Relation', 'Conjunctive']:\n",
    "    #         print(element)\n",
    "    \n",
    "    relations = [element for element in parser.subtrees() if element.label() in ['NP', 'Relation', 'Conjunctive']]\n",
    "    \n",
    "    noun_phrase_indexes = [index for index, element in enumerate(relations) if element.label() == \"NP\"]\n",
    "    \n",
    "    # print(noun_phrase_indexes)\n",
    "    \n",
    "    relationships = []\n",
    "    for index, element in enumerate(noun_phrase_indexes[::2]):\n",
    "        relationships.append(relations[noun_phrase_indexes[index]:noun_phrase_indexes[index + 1] + 1:])\n",
    "    \n",
    "    # ontology = {}\n",
    "        \n",
    "    # print(sentence)    \n",
    "    \n",
    "    for relationship in relationships:\n",
    "        conjunctive_relation = []\n",
    "        temp_relation = []\n",
    "        \n",
    "        first_concept = \" \".join([i[0] for i in relationship[0].leaves()])\n",
    "        \n",
    "        # print(first_concept.replace(\"Â¦ \", \"\"))\n",
    "        \n",
    "        # TODO: Make this work better make conjuctive relation addative\n",
    "        # In other words make conjunctive into [[]] with words added to [[\"is\", \"here\"]]\n",
    "        # then use conjunctive to add new value so [[\"is\", \"here\"], [\"is\", \"an\", \"animal\"]]\n",
    "        for element in relationship[1::]:\n",
    "            if element.label() == \"Relation\":\n",
    "                temp_relation.append(\" \".join(i[0] for i in element.leaves()))\n",
    "                for conjunctive_list in conjunctive_relation[::]:\n",
    "                    conjunctive_relation[-1].append(\" \".join(i[0] for i in element.leaves()))\n",
    "            elif element.label() == \"Conjunctive\":\n",
    "                conjunctive_relation.append(temp_relation)\n",
    "                conjunctive_relation.append(temp_relation[:-1:])\n",
    "                \n",
    "                # for conjuctive_list in conjunctive_relation:\n",
    "                # temp_relation.append(\" \".join(i[0] for i in element.leaves()))\n",
    "                # conjunctive_relation.append(temp_relation)\n",
    "                # conjunctive_relation.append(temp_relation[:-1:].append(\" \".join(i[0] for i in element.leaves())))\n",
    "                \n",
    "            elif element.label() == \"NP\":\n",
    "                temp_relation.append(\"::\" + \" \".join(i[0] for i in element.leaves()))\n",
    "                for conjuctive_list in conjunctive_relation:\n",
    "                    conjunctive_list.append(\"::\" + \" \".join(i[0] for i in element.leaves()))\n",
    "            # print(element)\n",
    "            \n",
    "            # print(element)\n",
    "        # print(temp_relation)\n",
    "        print(conjunctive_relation)\n",
    "            \n",
    "        print(\"-\" * 100)\n",
    "            \n",
    "        # first_concept = \" \".join([i[0] for i in relationship[0].leaves()])\n",
    "        # \n",
    "        # rel = \" \".join(\" \".join([j[0] for j in i.leaves()]) for i in relationship[1::] if i.label() != \"NP\")\n",
    "        # rel = f\"{rel}::{' '.join([i[0] for i in relationship[-1].leaves()])}\"\n",
    "        # \n",
    "        # if first_concept not in ontology.keys():\n",
    "        #     ontology[first_concept] = []\n",
    "        # ontology[first_concept].append(rel)\n",
    "        \n",
    "print(ontology)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}