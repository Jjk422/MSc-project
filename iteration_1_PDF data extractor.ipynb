{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import print_metrics\n",
    "\n",
    "file_path = \"ITIL Books/ITIL 3/ITIL3 Service Operation chapter 4.pdf\"\n",
    "# extracted_text_file_path = \"ITIL Books/ITIL 3/Continual service improvement chapter from notebook.txt\"\n",
    "# extracted_text_file_path = \"ITIL Books/ITIL 3/Service operation chapter 4/Service operation chapter 4 - 4.txt\"\n",
    "# extracted_text_file_path = \"ITIL Books\\ITIL 3\\Service operation chapter 4\\Automated concepts extracted\\\\4.2\\Service operation chapter 4 - 4.2 to 4.2.4 .txt\"\n",
    "output_file_path = \"output/ITIL3 Continual Service Improvement.txt\"\n",
    "\n",
    "### Chapter 4 start ###\n",
    "# extracted_text_file_path = print_metrics.get_extracted_text_file_path(4) \n",
    "# manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4)\n",
    "\n",
    "### Chapter 4 - 4.1 to 4.1.4 ###\n",
    "extracted_text_file_path = print_metrics.get_extracted_text_file_path(4.1) \n",
    "manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4.1)\n",
    "\n",
    "### Chapter 4 - 4.2 to 4.2.4 ###\n",
    "# extracted_text_file_path = print_metrics.get_extracted_text_file_path(4.2) \n",
    "# manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4.2)\n",
    "# \n",
    "# ### Chapter 4 - 4.3 to 4.3.4 ###\n",
    "# extracted_text_file_path = print_metrics.get_extracted_text_file_path(4.3) \n",
    "# manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4.3)\n",
    "# \n",
    "# ### Chapter 4 - 4.4 to 4.4.4 ###\n",
    "# extracted_text_file_path = print_metrics.get_extracted_text_file_path(4.4) \n",
    "# manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4.4)\n",
    "# \n",
    "# ### Chapter 4 - 4.5 to 4.5.4 ###\n",
    "# extracted_text_file_path = print_metrics.get_extracted_text_file_path(4.5) \n",
    "# manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4.5)\n",
    "# \n",
    "# ### Chapter 4 - 4.6 to 4.6.4 ###\n",
    "# extracted_text_file_path = print_metrics.get_extracted_text_file_path(4.6) \n",
    "# manual_concepts_file_path = print_metrics.get_manual_concepts_file_path(4.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pdfminer\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open(extracted_text_file_path, 'r') as file:\n",
    "    extracted_text = file.read()\n",
    "    \n",
    "# extracted_text = \"Particle dynamics involves the study of physics and chemistry\"\n",
    "\n",
    "# tokens = nltk.word_tokenize(extracted_text)\n",
    "# print(tokens)\n",
    "\n",
    "# ### Part of speech tagging ###\n",
    "# part_of_speech_array = nltk.pos_tag(tokens)\n",
    "# print(part_of_speech_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    },
    "scrolled": false
   },
   "source": [
    "Text sanitization and word tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Grab sections from text ###\n",
    "# print(re.findall(\"^\\d(\\.|\\d)*(\\s|\\w)*$\", extracted_text))\n",
    "# title_pattern = re.compile(r\"^\\d(\\.|\\d)*(\\s|\\w)*$\", re.MULTILINE)\n",
    "title_pattern = re.compile(r\"^\\d+.*$\", re.MULTILINE)\n",
    "\n",
    "sections = title_pattern.findall(extracted_text)\n",
    "for counter, section in enumerate(sections):\n",
    "    if not (section.find(\"%\") == -1 and section.find(\")\") == -1):\n",
    "        sections.remove(section)\n",
    "\n",
    "### Sanitise extracted text ###\n",
    "extracted_text_sanitised = extracted_text\n",
    "extracted_text_sanitised = extracted_text.replace(\"¦\", \"\")\n",
    "extracted_text_sanitised = extracted_text_sanitised.replace(\"–\", \"\")\n",
    "        \n",
    "### Tokenise extracted text ###\n",
    "tokens = nltk.word_tokenize(extracted_text_sanitised)\n",
    "# print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part to speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Part of speech tagging ###\n",
    "part_of_speech_array = nltk.pos_tag(tokens)\n",
    "# print(part_of_speech_array)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_part_of_speech_array(part_of_speech_array):\n",
    "    part_of_speech_array_lemmatized = []\n",
    "    \n",
    "    for part_of_speech in part_of_speech_array:\n",
    "        part_of_speech_array_lemmatized.append(\n",
    "            (lemmatizer.lemmatize(part_of_speech[0]), part_of_speech[1])\n",
    "        ) \n",
    "    return part_of_speech_array_lemmatized\n",
    "    \n",
    "# print(part_of_speech_array_lemmatized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Term extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "major named concepts: \n['EVENT MANAGEMENT', 'IT Infrastructure', 'IT', 'IT', 'Configuration Item', 'CI', 'Service Operation', 'CIs', 'ï¿½', 'CIs', 'Purpose/goal/objective', 'Event Management', 'Event Management', 'Operational Monitoring', 'Control', 'Appendix B', 'Operations Management', 'Event Management', 'Service Operation', 'SLAs', 'Event Management', 'Service Assurance', 'Reporting', 'Service Improvement', 'Continual Service Improvement', 'Scope Event Management', 'Service Management', 'Configuration Items', 'CIs', 'Event Management', 'CIs', 'Event Management', 'CMS', 'Software', 'ï¿½ Security', 'Event Management', 'Management', 'IT Infrastructure', 'Management', 'Event Management', 'Value', 'Event Managementï¿½s', 'Event Management', 'Management', 'ï¿½', 'Service Management', 'Availability', 'Capacity Management', 'Event Management', 'Service Management', 'Management']\n\nother concepts: \n['event', 'occurrence', 'significance', 'management', 'delivery', 'service', 'evaluation', 'impact', 'deviation', 'services', 'Events', 'notifications', 'service', 'tool', 'status', 'infrastructure', 'deviation', 'operation', 'monitoring', 'control systems', 'types', 'tools', 'monitoring tools', 'status', 'availability', 'exceptions', 'alert', 'tool', 'team', 'action', 'monitoring tools', 'alerts', 'communications', 'ability', 'events', 'sense', 'control action', 'basis', 'addition', 'events', 'information', 'warnings', 'exceptions', 'basis', 'activities', 'example', 'scripts', 'devices', 'jobs', 'processing', 'demand', 'service', 'devices', 'performance', 'entry point', 'execution', 'activities', 'addition', 'way', 'performance', 'behaviour', 'design standards', 'basis', 'detail', 'publication', 'aspect', 'state', 'e.g', 'switch', 'network', 'confirm', 'responses', 'status', 'e.g', 'updating', 'file server', 'conditions', 'e.g', 'fire', 'detection', 'ï¿½', 'licence monitoring', 'usage', 'licence utilization', 'allocation', 'e.g', 'intrusion detection', 'activity', 'e.g', 'use', 'application', 'performance', 'server', 'difference', 'monitoring', 'areas', 'nature', 'notifications', 'status', 'services', 'monitoring', 'notifications', 'monitoring', 'example', 'monitoring tools', 'status', 'device', 'limits', 'device', 'events', 'occurrences', 'tracks', 'occurrences', 'conditions', 'events', 'business', 'value', 'business', 'basis', 'value', 'mechanisms', 'detection', 'incidents', 'cases', 'incident', 'group', 'action', 'service outage', 'types', 'activity', 'exception', 'need', 'monitoring', 'downtime', 'ï¿½', 'example', 'status changes', 'exceptions', 'person', 'team', 'response', 'performance', 'process', 'turn', 'business', 'basis', 'operations', 'efficiencies', 'resources', 'work', 'functionality', 'ways', 'business', 'technology', 'advantage']\n\nall noun phrases: \n['EVENT MANAGEMENT', 'event', 'occurrence', 'significance', 'management', 'IT Infrastructure', 'delivery', 'IT service', 'evaluation', 'impact', 'deviation', 'services', 'Events', 'notifications', 'IT service', 'Configuration Item', 'CI', 'tool', 'Service Operation', 'status', 'infrastructure', 'deviation', 'operation', 'monitoring', 'control systems', 'types', 'tools', 'monitoring tools', 'CIs', 'status', 'availability', 'exceptions', 'alert', 'tool', 'team', 'action ï¿½', 'monitoring tools', 'alerts', 'communications', 'CIs', 'Purpose/goal/objective', 'ability', 'events', 'sense', 'control action', 'Event Management', 'Event Management', 'basis', 'Operational Monitoring', 'Control', 'Appendix B', 'addition', 'events', 'information', 'warnings', 'exceptions', 'basis', 'Operations Management activities', 'example', 'scripts', 'devices', 'jobs', 'processing', 'demand', 'service', 'devices', 'performance', 'Event Management', 'entry point', 'execution', 'Service Operation', 'activities', 'addition', 'way', 'performance', 'behaviour', 'design standards', 'SLAs', 'Event Management', 'basis', 'Service Assurance', 'Reporting', 'Service Improvement', 'detail', 'Continual Service Improvement publication', 'Scope Event Management', 'aspect', 'Service Management', 'Configuration Items', 'CIs', 'state', 'e.g', 'switch', 'network', 'Event Management', 'confirm', 'responses', 'CIs', 'status', 'Event Management', 'CMS', 'e.g', 'updating', 'file server', 'conditions', 'e.g', 'fire', 'detection', 'ï¿½ Software licence monitoring', 'usage', 'licence utilization', 'allocation ï¿½ Security', 'e.g', 'intrusion detection', 'activity', 'e.g', 'use', 'application', 'performance', 'server', 'difference', 'monitoring', 'Event Management', 'areas', 'nature', 'Management', 'notifications', 'status', 'IT Infrastructure', 'services', 'monitoring', 'notifications', 'monitoring', 'Management', 'example', 'monitoring tools', 'status', 'device', 'limits', 'device', 'events', 'Event Management', 'occurrences', 'tracks', 'occurrences', 'conditions', 'events', 'Value', 'business Event Managementï¿½s value', 'business', 'basis', 'value', 'Event Management', 'mechanisms', 'detection', 'incidents', 'cases', 'incident', 'group', 'action', 'service outage', 'Management', 'types', 'activity', 'exception ï¿½', 'need', 'monitoring', 'downtime', 'ï¿½', 'Service Management', 'example', 'Availability', 'Capacity Management', 'Event Management', 'status changes', 'exceptions', 'person', 'team', 'response', 'performance', 'process', 'turn', 'business', 'Service Management', 'Management', 'basis', 'operations', 'efficiencies', 'resources', 'work', 'functionality', 'ways', 'business', 'technology', 'advantage']\n\nall noun phrases with adj: \n['EVENT MANAGEMENT', 'event', 'detectable', 'discernible occurrence', 'significance', 'management', 'IT Infrastructure', 'delivery', 'IT service', 'evaluation', 'impact', 'deviation', 'services', 'Events', 'notifications', 'IT service', 'Configuration Item', 'CI', 'tool', 'Effective Service Operation', 'dependent', 'status', 'infrastructure', 'deviation', 'normal', 'operation', 'good monitoring', 'control systems', 'types', 'tools', 'active monitoring tools', 'key CIs', 'status', 'availability', 'exceptions', 'alert', 'appropriate tool', 'team', 'action ï¿½ passive monitoring tools', 'operational alerts', 'communications', 'CIs', 'Purpose/goal/objective', 'ability', 'events', 'sense', 'appropriate control action', 'Event Management', 'Event Management', 'basis', 'Operational Monitoring', 'Control', 'Appendix B', 'addition', 'events', 'operational information', 'warnings', 'exceptions', 'basis', 'many routine Operations Management activities', 'example', 'scripts', 'remote devices', 'jobs', 'processing', 'demand', 'service', 'multiple devices', 'performance', 'Event Management', 'entry point', 'execution', 'many Service Operation', 'activities', 'addition', 'way', 'actual performance', 'behaviour', 'design standards', 'SLAs', 'such', 'Event Management', 'basis', 'Service Assurance', 'Reporting', 'Service Improvement', 'detail', 'Continual Service Improvement publication', 'Scope Event Management', 'aspect', 'Service Management', 'ï¿½ Configuration Items', 'CIs', 'constant state', 'e.g', 'switch', 'network', 'Event Management', 'confirm', 'responses', 'CIs', 'status', 'Event Management', 'CMS', 'e.g', 'updating', 'file server', 'ï¿½ Environmental conditions', 'e.g', 'fire', 'detection', 'ï¿½ Software licence monitoring', 'usage', 'optimum/legal licence utilization', 'allocation ï¿½ Security', 'e.g', 'intrusion detection', 'Normal activity', 'e.g', 'use', 'application', 'performance', 'server', 'difference', 'monitoring', 'Event Management', 'areas', 'related', 'different', 'nature', 'Event Management', 'meaningful notifications', 'status', 'IT Infrastructure', 'services', 'true', 'monitoring', 'notifications', 'monitoring', 'Event Management', 'example', 'monitoring tools', 'status', 'device', 'acceptable limits', 'device', 'events', 'Event Management', 'occurrences', 'tracks', 'occurrences', 'conditions', 'events', 'Value', 'business Event Managementï¿½s value', 'business', 'indirect', 'possible', 'basis', 'value', 'ï¿½ Event Management', 'mechanisms', 'early detection', 'incidents', 'many cases', 'possible', 'incident', 'appropriate group', 'action', 'actual service outage', 'Event Management', 'possible', 'types', 'automated activity', 'exception ï¿½', 'need', 'expensive', 'resource intensive real-time monitoring', 'downtime', 'ï¿½', 'other Service Management', 'such', 'example', 'Availability', 'Capacity Management', 'Event Management', 'status changes', 'exceptions', 'appropriate person', 'team', 'early response', 'performance', 'process', 'turn', 'business', 'effective', 'efficient Service Management overall', 'Event Management', 'basis', 'operations', 'efficiencies', 'expensive human resources', 'innovative work', 'such', 'new', 'improved functionality', 'new ways', 'business', 'technology', 'increased competitive advantage']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "### Term Extraction (NNP next to each other) ###\n",
    "def extract_terms(part_of_speech_array_array, tags_to_use):\n",
    "    terms_array = []\n",
    "    term_phrase = []\n",
    "    start_new_term = True\n",
    "    for index, part in enumerate(part_of_speech_array_array):\n",
    "        if(part[1] in tags_to_use):\n",
    "            term_phrase.append(part[0])\n",
    "            start_new_term = False if part_of_speech_array_array[index + 1][1] in tags_to_use else True\n",
    "\n",
    "            if start_new_term == True:\n",
    "                terms_array.append(\" \".join(term_phrase))\n",
    "                term_phrase = []\n",
    "    return terms_array\n",
    "\n",
    "### Term Extraction (NNP next to each other) ###\n",
    "def extract_terms_with_adj(part_of_speech_array_array, tags_to_use):\n",
    "    terms_array = []\n",
    "    term_phrase = []\n",
    "    start_new_term = True\n",
    "    for index, part in enumerate(part_of_speech_array_array):\n",
    "        if(part[1] in tags_to_use):\n",
    "            term_phrase.append(part[0])\n",
    "            start_new_term = False if part_of_speech_array_array[index + 1][1] in tags_to_use else True\n",
    "\n",
    "            if start_new_term == True:\n",
    "                terms_array.append(\" \".join(term_phrase))\n",
    "                term_phrase = []\n",
    "    return terms_array\n",
    "\n",
    "major_named_concepts = extract_terms(part_of_speech_array, {\"NNP\", \"NNPS\"})\n",
    "other_concepts = extract_terms(part_of_speech_array, {\"NN\", \"NNS\"})\n",
    "all_noun_phrases = extract_terms(part_of_speech_array, {\"NNP\", \"NNPS\", \"NN\", \"NNS\"})\n",
    "all_noun_phrases_with_adj = extract_terms_with_adj(part_of_speech_array, {\"NNP\", \"NNPS\", \"NN\", \"NNS\", \"JJ\"})\n",
    "\n",
    "print(f\"major named concepts: \\n{major_named_concepts}\")\n",
    "print(f\"\\nother concepts: \\n{other_concepts}\")\n",
    "print(f\"\\nall noun phrases: \\n{all_noun_phrases}\")\n",
    "print(f\"\\nall noun phrases with adj: \\n{all_noun_phrases_with_adj}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Major/common concept extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "major named concepts: \n[('Event Management', 10), ('CIs', 4), ('Management', 4), ('Service Management', 3), ('IT Infrastructure', 2), ('IT', 2), ('Service Operation', 2), ('ï¿½', 2), ('EVENT MANAGEMENT', 1), ('Configuration Item', 1), ('CI', 1), ('Purpose/goal/objective', 1), ('Operational Monitoring', 1), ('Control', 1), ('Appendix B', 1), ('Operations Management', 1), ('SLAs', 1), ('Service Assurance', 1), ('Reporting', 1), ('Service Improvement', 1), ('Continual Service Improvement', 1), ('Scope Event Management', 1), ('Configuration Items', 1), ('CMS', 1), ('Software', 1), ('ï¿½ Security', 1), ('Value', 1), ('Event Managementï¿½s', 1), ('Availability', 1), ('Capacity Management', 1)]\n\nother concepts: \n[('status', 5), ('monitoring', 5), ('basis', 5), ('e.g', 5), ('events', 4), ('performance', 4), ('business', 4), ('service', 3), ('notifications', 3), ('monitoring tools', 3), ('exceptions', 3), ('example', 3), ('deviation', 2), ('services', 2), ('tool', 2), ('types', 2), ('team', 2), ('action', 2), ('addition', 2), ('activities', 2), ('devices', 2), ('conditions', 2), ('detection', 2), ('ï¿½', 2), ('activity', 2), ('device', 2), ('occurrences', 2), ('value', 2), ('event', 1), ('occurrence', 1), ('significance', 1), ('management', 1), ('delivery', 1), ('evaluation', 1), ('impact', 1), ('Events', 1), ('infrastructure', 1), ('operation', 1), ('control systems', 1), ('tools', 1), ('availability', 1), ('alert', 1), ('alerts', 1), ('communications', 1), ('ability', 1), ('sense', 1), ('control action', 1), ('information', 1), ('warnings', 1), ('scripts', 1)]\n\nall noun phrases: \n[('Event Management', 10), ('status', 5), ('monitoring', 5), ('basis', 5), ('e.g', 5), ('CIs', 4), ('events', 4), ('performance', 4), ('Management', 4), ('notifications', 3), ('monitoring tools', 3), ('exceptions', 3), ('example', 3), ('Service Management', 3), ('business', 3), ('IT Infrastructure', 2), ('IT service', 2), ('deviation', 2), ('services', 2), ('tool', 2), ('Service Operation', 2), ('types', 2), ('team', 2), ('addition', 2), ('devices', 2), ('conditions', 2), ('detection', 2), ('activity', 2), ('device', 2), ('occurrences', 2), ('EVENT MANAGEMENT', 1), ('event', 1), ('occurrence', 1), ('significance', 1), ('management', 1), ('delivery', 1), ('evaluation', 1), ('impact', 1), ('Events', 1), ('Configuration Item', 1), ('CI', 1), ('infrastructure', 1), ('operation', 1), ('control systems', 1), ('tools', 1), ('availability', 1), ('alert', 1), ('action ï¿½', 1), ('alerts', 1), ('communications', 1)]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# concept_relationships = extract_terms(part_of_speech_array, {\"VP\"})\n",
    "# print(concept_relationships)\n",
    "# print(all_noun_phrases)\n",
    "\n",
    "### Perform frequency analysis ###\n",
    "### Concept Extraction Frequency analysis ###\n",
    "major_named_concept_frequency_distribution = nltk.FreqDist(major_named_concepts)\n",
    "other_concept_frequency_distribution = nltk.FreqDist(other_concepts)\n",
    "all_noun_phrases_frequency_distribution = nltk.FreqDist(all_noun_phrases)\n",
    "\n",
    "print(f\"major named concepts: \\n{major_named_concept_frequency_distribution.most_common(50)}\")\n",
    "print(f\"\\nother concepts: \\n{other_concept_frequency_distribution.most_common(50)}\")\n",
    "print(f\"\\nall noun phrases: \\n{all_noun_phrases_frequency_distribution.most_common(50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Concept relationship extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_sentence_at_index(part_of_speech_array, index):\n",
    "    sentence_starting_index = 0\n",
    "    sentence_end_index = len(part_of_speech_array)\n",
    "    \n",
    "    ### Get sentence start index ###\n",
    "    for i in range(0, index):\n",
    "#         print(part_of_speech_array[index])\n",
    "        if part_of_speech_array[index - i][1] == \".\":\n",
    "            sentence_starting_index = index - i\n",
    "            break\n",
    "    \n",
    "    ### Get sentence end index ###\n",
    "    for i in range(0, len(part_of_speech_array)):\n",
    "        if part_of_speech_array[index + i][1] == \".\":\n",
    "            sentence_end_index = index + i\n",
    "            break\n",
    "            \n",
    "    return (sentence_starting_index, sentence_end_index + 1)\n",
    "\n",
    "### Term Extraction (NNP next to each other) ###\n",
    "def extract_terms(part_of_speech_array_array, tags_to_use):\n",
    "    part_of_speech_array_with_terms = []\n",
    "    \n",
    "    terms_array = []\n",
    "    term_phrase = []\n",
    "    start_new_term = True\n",
    "    for index, part in enumerate(part_of_speech_array_array):\n",
    "        if(part[1] in tags_to_use):\n",
    "            term_phrase.append(part[0])\n",
    "            start_new_term = False if part_of_speech_array_array[index + 1][1] in tags_to_use else True\n",
    "\n",
    "            if start_new_term == True:\n",
    "                if len(term_phrase) > 1:\n",
    "#                     part_of_speech_array_with_terms.append((\" \".join(term_phrase), f\"NPhrase-{part[1]}\"))\n",
    "                    part_of_speech_array_with_terms.append((\" \".join(term_phrase), \"NPhrase\"))\n",
    "                else:\n",
    "                    part_of_speech_array_with_terms.append((\" \".join(term_phrase), part[1]))\n",
    "                term_phrase = []\n",
    "        else:\n",
    "            part_of_speech_array_with_terms.append((part[0], part[1]))\n",
    "    return part_of_speech_array_with_terms\n",
    "\n",
    "part_of_speech_array_with_terms = extract_terms(part_of_speech_array, {\"NNP\", \"NNPS\", \"NN\", \"NNS\"})\n",
    "# print(part_of_speech_array_with_terms)\n",
    "\n",
    "sentences = []\n",
    "temp_sentence = []\n",
    "for word in part_of_speech_array_with_terms:\n",
    "    if word[1] is \".\":\n",
    "        temp_sentence.append(word)\n",
    "        sentences.append(temp_sentence)\n",
    "        temp_sentence = []\n",
    "    else:\n",
    "        temp_sentence.append(word)\n",
    "        \n",
    "        \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# for index, sentence in enumerate(sentences):\n",
    "#     sentence_with_no_stop_words = [word_pos for word_pos in sentence if not word_pos[0] in stop_words]\n",
    "#     \n",
    "#     if index > 3:\n",
    "#         break\n",
    "#         \n",
    "#     print(sentence)\n",
    "#     print(sentence_with_no_stop_words)\n",
    "#     print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('provided', 'VBN'), ('by', 'IN'), ('good', 'JJ'), ('monitoring', 'NN'), ('and', 'CC'), ('control systems', 'NPhrase'), (',', ','), ('which', 'WDT'), ('are', 'VBP'), ('based', 'VBN'), ('on', 'IN'), ('two', 'CD'), ('types', 'NNS'), ('of', 'IN'), ('tools', 'NNS'), (':', ':'), ('ï¿½', 'RB'), ('active', 'JJ'), ('monitoring tools', 'NPhrase'), ('that', 'WDT'), ('poll', 'VBP'), ('key', 'JJ'), ('CIs', 'NNP'), ('to', 'TO'), ('determine', 'VB'), ('their', 'PRP$'), ('status', 'NN'), ('and', 'CC'), ('availability', 'NN'), ('.', '.')]\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-273c9ee1f2b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpart_of_speech_regex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPartOfSpeechRegex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mpart_of_speech_regex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseAndReturnPatterns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mpart_of_speech_regex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparseAndReturnPatterns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: parseAndReturnPatterns() missing 2 required positional arguments: 'pattern_string' and 'sentence'"
     ],
     "ename": "TypeError",
     "evalue": "parseAndReturnPatterns() missing 2 required positional arguments: 'pattern_string' and 'sentence'",
     "output_type": "error"
    }
   ],
   "source": [
    "# from part_of_speech_regex import PartOfSpeechRegex\n",
    "\n",
    "class PartOfSpeechRegex:\n",
    "    def parseAndReturnPatterns(self, pattern_string, sentence):\n",
    "        print(pattern_string)\n",
    "\n",
    "pattern_string = \"*<JJ><NNP><VBZ><NP>\"\n",
    "\n",
    "print(sentences[3])\n",
    "\n",
    "part_of_speech_regex = PartOfSpeechRegex()\n",
    "# part_of_speech_regex.parseAndReturnPatterns()\n",
    "\n",
    "part_of_speech_regex.parseAndReturnPatterns(pattern_string, sentences[3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%        \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "most_common_major_concepts = major_named_concept_frequency_distribution.most_common(50)\n",
    "# print(most_common_major_concepts)\n",
    "# print(tokens.index(most_common_major_concepts[0][0]))\n",
    "# print(part_of_speech_array[206])\n",
    "## Get indices of all common concepts\n",
    "indices = [i for i, x in enumerate(part_of_speech_array) if x[0] == most_common_major_concepts[0][0]]\n",
    "# print(indices)\n",
    "# print(most_common_major_concepts[1][0])\n",
    "\n",
    "def get_sentence_at_index(part_of_speech_array, index):\n",
    "    sentence_starting_index = 0\n",
    "    sentence_end_index = len(part_of_speech_array)\n",
    "    \n",
    "    ### Get sentence start index ###\n",
    "    for i in range(0, index):\n",
    "        if part_of_speech_array[index - i][1] == \".\":\n",
    "            sentence_starting_index = index - i\n",
    "            break\n",
    "    \n",
    "    ### Get sentence end index ###\n",
    "    for i in range(0, index):\n",
    "        if part_of_speech_array[index + i][1] == \".\":\n",
    "            sentence_end_index = index + i\n",
    "            break\n",
    "            \n",
    "    return (sentence_starting_index + 1, sentence_end_index + 1)\n",
    "\n",
    "def does_list_contain_verb_pos(part_of_speech_array):\n",
    "    for word_pos in part_of_speech_array:\n",
    "        if word_pos[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "# sentence_index = get_sentence_at_index(part_of_speech_array, indices[0])\n",
    "# print(sentence_index)\n",
    "\n",
    "concept_relations = []\n",
    "\n",
    "i = 0\n",
    "for index in indices:\n",
    "#     if i < 3:\n",
    "#         i = i + 1\n",
    "#         continue\n",
    "    sentence_pos_containing_concept = part_of_speech_array[\n",
    "        get_sentence_at_index(part_of_speech_array, index)[0]:\n",
    "        get_sentence_at_index(part_of_speech_array, index)[1]\n",
    "    ]\n",
    "    print(sentence_pos_containing_concept)\n",
    "        \n",
    "    last_concept = ()\n",
    "    last_concept_index = -1\n",
    "    # For word part_of_speech in sentence_part_of_speech_containing_concept\n",
    "    for index, word_pos in enumerate(sentence_pos_containing_concept):\n",
    "#         print(f\"{word_pos[0]}: {word_pos[1]}\")\n",
    "#         print(word_pos[0] in all_noun_phrases)\n",
    "        \n",
    "#         if (word_pos[0] in all_noun_phrases):\n",
    "        if (word_pos[0] in major_named_concepts):\n",
    "            if last_concept_index != -1:# and does_list_contain_verb_pos(sentence_pos_containing_concept[last_concept_index + 1:index]):\n",
    "                concept_relations.append(f\"{last_concept}::{sentence_pos_containing_concept[last_concept_index + 1:index]}::{word_pos}\")\n",
    "            \n",
    "            last_concept = word_pos\n",
    "            last_concept_index = index\n",
    "        \n",
    "    # print(related_concepts)\n",
    "    # print()\n",
    "    \n",
    "#     print('-----')\n",
    "    i = i + 1\n",
    "#     if i == 4:\n",
    "#         break\n",
    "\n",
    "# for concept_relation in concept_relations:\n",
    "#     print(concept_relation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Metrics for term extraction chapter 4 first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### The below cell code is now within the print_metrics python file so it can be used for iteration 1 and 2 without duplication\n",
    "# # automatic_concepts_file_path = \"ITIL Books/ITIL 3/Service operation chapter 4/Automated concepts extracted/4/Automated concepts extracted 4.txt\"\n",
    "# # manual_concepts_file_path = \"ITIL Books/ITIL 3/Service operation chapter 4/Automated concepts extracted/4/Manual concepts extracted 4.txt\"\n",
    "# \n",
    "# # automatic_concepts_file_path = \"ITIL Books/ITIL 3/Service operation chapter 4/Automated concepts extracted/4.2/Automated concepts extracted 4.2.txt\"\n",
    "# # manual_concepts_file_path = \"ITIL Books/ITIL 3/Service operation chapter 4/Automated concepts extracted/4.2/Manual concepts extracted 4.2.txt\"\n",
    "# # \n",
    "# # with open(automatic_concepts_file_path, 'r') as file:\n",
    "# #     automatic_concepts = file.read()\n",
    "# \n",
    "# with open(manual_concepts_file_path, 'r') as file:\n",
    "#     manual_concepts = file.read()\n",
    "# \n",
    "# manual_concepts_list = manual_concepts.split('\\n')\n",
    "# manual_concepts_list = [x.lower() for x in manual_concepts_list]\n",
    "# \n",
    "# # print(\"Manual concepts\")\n",
    "# # print(list(dict.fromkeys(manual_concepts_list)))\n",
    "# # print()\n",
    "# \n",
    "# # automatic_concepts_list = ['Service Operation', 'processes', 'paragraph', 'detail', 'chapter', 'reference', 'structure', 'processes', 'detail', 'chapter', 'Please note', 'roles', 'process', 'tools', 'process', 'Chapters', 'Management', 'process', 'monitors', 'events', 'IT infrastructure', 'operation', 'exception conditions', 'Incident Management', 'service', 'users', 'order', 'business impact', 'Problem Management', 'root-cause analysis', 'cause', 'events', 'incidents', 'activities', 'problems/incidents', 'Known Error subprocess', 'quicker diagnosis', 'resolution', 'incidents', 'NOTE', 'distinction', 'incidents', 'problems', 'Incident', 'Problem Records', 'danger', 'Incidents', 'support cycle', 'actions', 'recurrence', 'incidents', 'Incidents', 'root cause analysis', 'visibility', 'user ’ s service', 'SLA targets', 'service', 'users', 'expectations', 'results', 'number', 'incidents', '‘ purge ’', 'visibility', 'issues', 'Request Fulfilment', 'management', 'customer', 'user requests', 'incident', 'service delay', 'disruption', 'organizations', 'requests', 'category ’', 'incidents', 'information', 'Incident Management system', 'others', 'volumes', 'business priority', 'requests', 'provision', 'Request Fulfilment', 'Request Fulfilment process', 'practice', 'Request Fulfilment process', 'customer', 'user requests', 'types', 'requests', 'facilities', 'moves', 'supplies', 'IT services', 'requests', 'SLA measures', 'records', 'process flow', 'practice', 'organizations', 'Access Management', 'process', 'users', 'right', 'service', 'access', 'users', 'users', 'ability', 'access services', 'stages', 'resources', 'HR', 'lifecycle', 'Access Management', 'Identity', 'Rights Management', 'organizations', 'addition', 'processes', 'Service Operation', 'phases', 'Service Management Lifecycle', 'aspects', 'processes', 'part', 'chapter', 'include', 'Change Management', 'process', 'Configuration Management', 'Release Management', 'topics', 'Service Transition publication', 'Capacity', 'Availability Management', 'aspects', 'publication', 'detail', 'Service Design publication', 'Financial Management', 'Service Strategy publication', 'Knowledge Management', 'Service Transition publication', 'IT Service Continuity', 'Service Design publication', 'Service Reporting', 'Measurement', 'Continual Service Improvement publication']\n",
    "# automatic_concepts_list = all_noun_phrases\n",
    "# automatic_concepts_list = [x.lower() for x in automatic_concepts_list]\n",
    "# \n",
    "# # print(\"all noun phrases\")\n",
    "# # print(list(dict.fromkeys(automatic_concepts_list)))\n",
    "# \n",
    "# count = 0\n",
    "# for concept in manual_concepts_list:\n",
    "#     if concept in automatic_concepts_list:\n",
    "#         count = count + 1\n",
    "# \n",
    "# number_of_fully_correct_manual_concepts = count\n",
    "# \n",
    "# number_of_manual_concepts = len(manual_concepts_list)\n",
    "# \n",
    "# count = 0\n",
    "# for concept in automatic_concepts_list:\n",
    "#     if concept in manual_concepts_list:\n",
    "#         count = count + 1\n",
    "#     \n",
    "# number_of_fully_correct_automatic_concepts = count\n",
    "# \n",
    "# number_of_automatic_concepts = len(automatic_concepts_list)\n",
    "# \n",
    "# print(f\"number_of_manual_concepts: {number_of_manual_concepts}\")\n",
    "# print(f\"number_of_automatic_concepts: {number_of_automatic_concepts}\")\n",
    "# print(f\"number_of_fully_correct_manual_concepts: {number_of_fully_correct_manual_concepts}\")\n",
    "# print(f\"number_of_fully_correct_automatic_concepts: {number_of_fully_correct_automatic_concepts}\")\n",
    "# \n",
    "# # Lists to words for partial matches\n",
    "# automatic_concepts_list_single_words = [x.split() for x in automatic_concepts_list]\n",
    "# # print(automatic_concepts_list_single_words)\n",
    "# \n",
    "# manual_concepts_list_single_words = [x.split() for x in manual_concepts_list]\n",
    "# # print(manual_concepts_list_single_words)\n",
    "# \n",
    "# count = 0\n",
    "# for concept in manual_concepts_list_single_words:\n",
    "#     for word in concept:\n",
    "#         if word in ' '.join(automatic_concepts_list).split():\n",
    "#             count = count + 1\n",
    "#             break\n",
    "#         \n",
    "# number_of_full_and_partial_correct_manual_concepts = count\n",
    "# print(f\"number_of_full_and_partial_correct_manual_concepts: {number_of_full_and_partial_correct_manual_concepts}\")\n",
    "# \n",
    "# count = 0\n",
    "# for concept in automatic_concepts_list_single_words:\n",
    "#     for word in concept:\n",
    "#         if word in ' '.join(manual_concepts_list).split():\n",
    "#             count = count + 1\n",
    "#             break\n",
    "#             \n",
    "# number_of_full_and_partial_correct_automatic_concepts = count\n",
    "# print(f\"number_of_full_and_partial_correct_automatic_concepts: {number_of_full_and_partial_correct_automatic_concepts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "All noun phrases\n['EVENT MANAGEMENT', 'event', 'occurrence', 'significance', 'management', 'IT Infrastructure', 'delivery', 'IT service', 'evaluation', 'impact', 'deviation', 'services', 'Events', 'notifications', 'IT service', 'Configuration Item', 'CI', 'tool', 'Service Operation', 'status', 'infrastructure', 'deviation', 'operation', 'monitoring', 'control systems', 'types', 'tools', 'monitoring tools', 'CIs', 'status', 'availability', 'exceptions', 'alert', 'tool', 'team', 'action ï¿½', 'monitoring tools', 'alerts', 'communications', 'CIs', 'Purpose/goal/objective', 'ability', 'events', 'sense', 'control action', 'Event Management', 'Event Management', 'basis', 'Operational Monitoring', 'Control', 'Appendix B', 'addition', 'events', 'information', 'warnings', 'exceptions', 'basis', 'Operations Management activities', 'example', 'scripts', 'devices', 'jobs', 'processing', 'demand', 'service', 'devices', 'performance', 'Event Management', 'entry point', 'execution', 'Service Operation', 'activities', 'addition', 'way', 'performance', 'behaviour', 'design standards', 'SLAs', 'Event Management', 'basis', 'Service Assurance', 'Reporting', 'Service Improvement', 'detail', 'Continual Service Improvement publication', 'Scope Event Management', 'aspect', 'Service Management', 'Configuration Items', 'CIs', 'state', 'e.g', 'switch', 'network', 'Event Management', 'confirm', 'responses', 'CIs', 'status', 'Event Management', 'CMS', 'e.g', 'updating', 'file server', 'conditions', 'e.g', 'fire', 'detection', 'ï¿½ Software licence monitoring', 'usage', 'licence utilization', 'allocation ï¿½ Security', 'e.g', 'intrusion detection', 'activity', 'e.g', 'use', 'application', 'performance', 'server', 'difference', 'monitoring', 'Event Management', 'areas', 'nature', 'Management', 'notifications', 'status', 'IT Infrastructure', 'services', 'monitoring', 'notifications', 'monitoring', 'Management', 'example', 'monitoring tools', 'status', 'device', 'limits', 'device', 'events', 'Event Management', 'occurrences', 'tracks', 'occurrences', 'conditions', 'events', 'Value', 'business Event Managementï¿½s value', 'business', 'basis', 'value', 'Event Management', 'mechanisms', 'detection', 'incidents', 'cases', 'incident', 'group', 'action', 'service outage', 'Management', 'types', 'activity', 'exception ï¿½', 'need', 'monitoring', 'downtime', 'ï¿½', 'Service Management', 'example', 'Availability', 'Capacity Management', 'Event Management', 'status changes', 'exceptions', 'person', 'team', 'response', 'performance', 'process', 'turn', 'business', 'Service Management', 'Management', 'basis', 'operations', 'efficiencies', 'resources', 'work', 'functionality', 'ways', 'business', 'technology', 'advantage']\nmanual concepts\n['event management', 'event', 'occurrence', 'management', 'it infrastructure', 'delivery', 'it service', 'services', 'events', 'notifications', 'it service', 'configuration item (ci)', 'monitoring tool', 'effective service operation', 'infrastructure', 'normal or expected operation', 'monitoring and control systems', 'tools', 'active monitoring tools', 'key cis', 'status', 'availability', 'alert', 'appropriate tool', 'team', 'action', 'passive monitoring tools', 'operational alerts', 'communications', 'cis', 'purpose/goal/objective', 'events', 'control action', 'event management', 'event management', 'operational monitoring and control', 'events', 'programmed', 'operational monitoring and control', 'events', 'programmed', 'operational information', 'warnings', 'expectations', 'operations management activities', 'scripts', 'remote devices', 'jobs', 'demand', 'service', 'multiple devices', 'enhance performance', 'event management', 'execution', 'service operation processes', 'activities', 'performance', 'behaviour', 'design standards', 'slas', 'event management', 'service assurance', 'reporting', 'service improvement', 'continual service improvement publication', 'scope', 'event management', 'service management', 'configuration items', 'cis', 'constant state', 'switch on a network', 'event management tools', 'monitoring', 'pings', 'cis', 'status', 'event management', 'cms', 'file server', 'environmental conditions', 'fire', 'smoke detection', 'software licence monitoring', 'usage', 'optimum/legal licence utilization', 'allocation', 'security', 'intrusion detection', 'normal activity', 'service', 'monitoring', 'event management', 'event management', 'meaningful notifications', 'status', 'it infrastructure and services', 'notifications', 'monitoring', 'event management', 'monitoring tools', 'status', 'device', 'acceptable limits', 'device', 'events', 'event management', 'monitored', 'monitoring', 'events', 'value to business', \"event management's value\", 'business', 'value', 'event management', 'detection of incidents', 'incident', 'group', 'action', 'service outage', 'event management', 'types of automated activity', 'exception', 'resource intensive real-time monitoring', 'service management processes', 'availability', 'capacity management', 'event management', 'status changes', 'exceptions', 'person', 'team', 'early response', 'performance', 'process', 'business', 'service management', 'event management', 'automated operations', 'increasing efficiencies', 'expensive human resources', 'innovative work', 'functionality', 'business', 'competitive advantage']\nnumber_of_manual_concepts: 145\nnumber_of_automatic_concepts: 195\nnumber_of_fully_correct_manual_concepts: 96\nnumber_of_fully_correct_automatic_concepts: 107\nnumber_of_full_and_partial_correct_manual_concepts: 140\nnumber_of_full_and_partial_correct_automatic_concepts: 147\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import print_metrics\n",
    "\n",
    "part_of_speech_array = nltk.pos_tag(tokens)\n",
    "lemmatized_part_of_speech_array = lemmatize_part_of_speech_array(part_of_speech_array)\n",
    "\n",
    "extract_terms(part_of_speech_array, {\"NNP\", \"NNPS\", \"NN\", \"NNS\"})\n",
    "extract_terms(lemmatized_part_of_speech_array, {\"NNP\", \"NNPS\", \"NN\", \"NNS\"})\n",
    "\n",
    "print_metrics.print_metrics(manual_concepts_file_path, all_noun_phrases, debug=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}