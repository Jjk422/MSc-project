{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part of speech grammer parser\n",
    "Use template to grab words that fit with the part of speech grammar pattern.  \n",
    "Examples of the format of the grammar parser are:  \n",
    "* `<DT><NN><VB><NN>`\n",
    " * Returns `<DT><NN><VBZ><NN>`\n",
    " * e.g. The cat plays piano\n",
    "* `!<DT><NN><VB><NN>`\n",
    " * Returns `<NN><VBZ><NN>`\n",
    " * e.g. cat plays piano\n",
    "* `<DT><NN>*<NN>`\n",
    " * Returns `<DT><NN><VBZ><NN>`\n",
    " * e.g. The cat plays piano\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('Event', 'JJ'), ('Management', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('process', 'NN'), ('that', 'IN'), ('monitors', 'NNS'), ('all', 'DT'), ('events', 'NNS'), ('that', 'WDT'), ('occur', 'VBP'), ('through', 'IN'), ('the', 'DT'), ('IT', 'NNP'), ('infrastructure', 'NN'), ('to', 'TO'), ('allow', 'VB'), ('for', 'IN'), ('normal', 'JJ'), ('operation', 'NN'), ('and', 'CC'), ('also', 'RB'), ('to', 'TO'), ('detect', 'VB'), ('and', 'CC'), ('escalate', 'VB'), ('exception', 'NN'), ('conditions', 'NNS'), ('.', '.')]\n----------------------------------------------------------------------------------------------------\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import nltk\n",
    "# sentence = \"The cat plays piano.\"\n",
    "sentence = \"Event Management is the process that monitors all events that occur through the IT infrastructure to allow for normal operation and also to detect and escalate exception conditions.\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "### Part of speech tagging ###\n",
    "part_of_speech_array = nltk.pos_tag(tokens)\n",
    "print(part_of_speech_array)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# def search_pos_sentence_with_grammar(grammar, sentence, ordering):\n",
    "#     tags_to_search_for = []\n",
    "#     for all_pos_tags in grammar:\n",
    "#         all_pos_tags = all_pos_tags.split(\"/\")\n",
    "#         # print(all_pos_tags)\n",
    "#         tags_to_search_for.append(all_pos_tags)\n",
    "#         \n",
    "#     print(tags_to_search_for)\n",
    "#     \n",
    "#     phrase = []\n",
    "#     found_start_word = False\n",
    "#     tag_count = 0\n",
    "#     word_count = 0\n",
    "#     for pos_word in sentence:\n",
    "#         if tag_count < len(tags_to_search_for) and pos_word[1] in tags_to_search_for[tag_count]:\n",
    "#             if ordering is True:\n",
    "#                 \n",
    "#             tag_count = tag_count + 1\n",
    "#             phrase.append(pos_word)\n",
    "#         word_count = word_count + 1\n",
    "#     print(phrase)\n",
    "#     return phrase\n",
    "#         \n",
    "#         \n",
    "#     \n",
    "#         \n",
    "# def pos_grammar_parse(grammar, sentence, ordering=False):\n",
    "#     grammar = [item.replace(\"<\", \"\").upper() for item in grammar.split(\">\") if item is not '']\n",
    "#     # grammar = [item.split(\"/\") for item in grammar]\n",
    "#     # print(grammar)\n",
    "#     return search_pos_sentence_with_grammar(grammar, sentence, ordering)\n",
    "#     # print(grammar)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('Event', 'JJ'), ('Management', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('process', 'NN'), ('that', 'IN'), ('monitor', 'NNS'), ('all', 'DT'), ('event', 'NNS'), ('that', 'WDT'), ('occur', 'VBP'), ('through', 'IN'), ('the', 'DT'), ('IT', 'NNP'), ('infrastructure', 'NN'), ('to', 'TO'), ('allow', 'VB'), ('for', 'IN'), ('normal', 'JJ'), ('operation', 'NN'), ('and', 'CC'), ('also', 'RB'), ('to', 'TO'), ('detect', 'VB'), ('and', 'CC'), ('escalate', 'VB'), ('exception', 'NN'), ('condition', 'NNS'), ('.', '.')]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "part_of_speech_array_lemmatized = []\n",
    "\n",
    "for part_of_speech in part_of_speech_array:\n",
    "    part_of_speech_array_lemmatized.append(\n",
    "        (lemmatizer.lemmatize(part_of_speech[0]), part_of_speech[1])\n",
    "    ) \n",
    "\n",
    "print(part_of_speech_array_lemmatized)\n",
    "\n",
    "# print(part_of_speech_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[('Event', 'JJ'), ('Management', 'NNP'), ('process', 'NN'), ('monitor', 'NNS'), ('event', 'NNS'), ('occur', 'VBP'), ('IT', 'NNP'), ('infrastructure', 'NN'), ('allow', 'VB'), ('normal', 'JJ'), ('operation', 'NN'), ('also', 'RB'), ('detect', 'VB'), ('escalate', 'VB'), ('exception', 'NN'), ('condition', 'NNS'), ('.', '.')]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "part_of_speech_array_lemmatized_no_stopwords = [word_pos for word_pos in part_of_speech_array_lemmatized if not word_pos[0] in stop_words]\n",
    "\n",
    "print(part_of_speech_array_lemmatized_no_stopwords)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n(Relation (NP Event/JJ Management/NNP) is/VBZ)\n(Relation (NP process/NN) that/IN (NP monitor/NNS))\n(Relation occur/VBP through/IN)\n(Relation allow/VB for/IN (NP normal/JJ operation/NN))\n(Relation detect/VB)\n(Relation escalate/VB (NP exception/NN condition/NNS))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# noun_phrase_grammar = \"NP: {<DT>?<JJ>*<NN|NNP|NNS>*}\"\n",
    "# noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>*}\"\n",
    "noun_phrase_grammar = \"NP: {<JJ>*<NN|NNP|NNS>+}\"\n",
    "# print(pos_grammar_parse(grammar, part_of_speech_array))\n",
    "\n",
    "regex = nltk.RegexpParser(noun_phrase_grammar)\n",
    "noun_phrases_chunked = regex.parse(part_of_speech_array_lemmatized)\n",
    "noun_phrases = [item for item in noun_phrases_chunked.subtrees() if item.label() == \"NP\"]\n",
    "\n",
    "# print(noun_phrases)\n",
    "\n",
    "# for item in noun_phrases_chunked:\n",
    "#     print(item)\n",
    "# print()\n",
    "# \n",
    "# for concept in noun_phrases:\n",
    "#     print(concept)\n",
    "#     \n",
    "# print()\n",
    "\n",
    "relation_grammer = \"\"\"\n",
    "    Relation: {<NP>?.*?<VBZ|VBP|IN|VB>+.*?<NP>?}\n",
    "    \"\"\"\n",
    "regex = nltk.RegexpParser(relation_grammer)\n",
    "parser = regex.parse(noun_phrases_chunked)\n",
    "relation_phrases = [item for item in parser.subtrees() if item.label() == \"Relation\"]\n",
    "\n",
    "# print(relation_phrases)\n",
    "\n",
    "# for parse in parser:\n",
    "#     print(parse)\n",
    "\n",
    "relation_new = []\n",
    "# TODO: Find a less hacky way to do this\n",
    "for index, relation in enumerate(relation_phrases):\n",
    "    # print(relation)\n",
    "\n",
    "    temp_relation = []\n",
    "    if index is not 0:\n",
    "        temp_relation.append(relation_phrases)\n",
    "        temp_relation.append(item for item in relation)\n",
    "        # print(f\"TEMP RELATION: {temp_relation}\")\n",
    "        relation = temp_relation\n",
    "\n",
    "    # print(temp_relation)\n",
    "    relation_new.append(relation)\n",
    "    # print(relation_new)\n",
    "\n",
    "print()\n",
    "\n",
    "# for relation in relation_new:\n",
    "#     for item in relation:\n",
    "#         print(item)\n",
    "    \n",
    "for relation in relation_phrases:\n",
    "    print(relation)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}